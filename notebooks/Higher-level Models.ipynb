{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To obtain higher classification accuracy, we implemented neural networks, which we did not learn in the class. Multi-layer perceptrons neural network is a supervised method, and is very powerful in classifying Alzheimer's disease as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "df_train = pd.read_csv(\"data/ADNIMERGE_train.csv\")\n",
    "df_test = pd.read_csv(\"data/ADNIMERGE_test.csv\")\n",
    "X_train = df_train.drop(['RID', 'DX_bl'], axis=1).copy()\n",
    "y_train = df_train['DX_bl'].copy()\n",
    "X_test = df_test.drop(['RID', 'DX_bl'], axis=1).copy()\n",
    "y_test = df_test['DX_bl'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to help compare the accuracy of models\n",
    "def score(model, X_train, y_train, X_test, y_test):\n",
    "    train_acc = model.score(X_train,y_train)\n",
    "    test_acc = model.score(X_test,y_test)\n",
    "    test_class0 = model.score(X_test[y_test==0], y_test[y_test==0])\n",
    "    test_class1 = model.score(X_test[y_test==1], y_test[y_test==1])\n",
    "    test_class2 = model.score(X_test[y_test==2], y_test[y_test==2])\n",
    "    return pd.Series([train_acc, test_acc, test_class0, test_class1, test_class2],\n",
    "                    index = ['Train accuracy', 'Test accuracy', \n",
    "                             \"Test accuracy CN\", \"Test accuracy CI\", \"Test accuracy AD\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols_standardize = [\n",
    "    c for c in X_train.columns \n",
    "    if (not c.startswith('PT')) or (c=='PTEDUCAT')]\n",
    "\n",
    "X_train_std = X_train.copy()\n",
    "X_test_std = X_test.copy()\n",
    "for c in cols_standardize:\n",
    "    col_mean = np.mean(X_train[c])\n",
    "    col_sd = np.std(X_train[c])\n",
    "    if col_sd > (1e-10)*col_mean:\n",
    "        X_train_std[c] = (X_train[c]-col_mean)/col_sd\n",
    "        X_test_std[c] = (X_test[c]-col_mean)/col_sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(621, 74)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PTGENDER</th>\n",
       "      <th>PTEDUCAT</th>\n",
       "      <th>PTRACCAT_Asian</th>\n",
       "      <th>PTRACCAT_Black</th>\n",
       "      <th>PTRACCAT_Hawaiian/Other_PI</th>\n",
       "      <th>PTRACCAT_More_than_one</th>\n",
       "      <th>PTRACCAT_Unknown</th>\n",
       "      <th>PTRACCAT_White</th>\n",
       "      <th>PTETHCAT_Not_Hisp/Latino</th>\n",
       "      <th>PTMARRY_Married</th>\n",
       "      <th>...</th>\n",
       "      <th>WholeBrain</th>\n",
       "      <th>WholeBrain_slope</th>\n",
       "      <th>Entorhinal</th>\n",
       "      <th>Entorhinal_slope</th>\n",
       "      <th>Fusiform</th>\n",
       "      <th>Fusiform_slope</th>\n",
       "      <th>MidTemp</th>\n",
       "      <th>MidTemp_slope</th>\n",
       "      <th>ICV</th>\n",
       "      <th>ICV_slope</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-2.852257</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.761500</td>\n",
       "      <td>-0.567555</td>\n",
       "      <td>-0.820814</td>\n",
       "      <td>-1.269796</td>\n",
       "      <td>-1.426968</td>\n",
       "      <td>0.156847</td>\n",
       "      <td>-2.102069</td>\n",
       "      <td>-0.192827</td>\n",
       "      <td>-1.574482</td>\n",
       "      <td>0.093937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.376909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.134464</td>\n",
       "      <td>-0.028641</td>\n",
       "      <td>-0.070387</td>\n",
       "      <td>0.188014</td>\n",
       "      <td>0.721399</td>\n",
       "      <td>-0.067438</td>\n",
       "      <td>0.019784</td>\n",
       "      <td>0.506511</td>\n",
       "      <td>-0.489132</td>\n",
       "      <td>-0.265646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.607970</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.300396</td>\n",
       "      <td>0.310720</td>\n",
       "      <td>0.456478</td>\n",
       "      <td>-0.560840</td>\n",
       "      <td>0.292776</td>\n",
       "      <td>0.016824</td>\n",
       "      <td>-0.650452</td>\n",
       "      <td>0.224140</td>\n",
       "      <td>-1.239633</td>\n",
       "      <td>-0.014198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.160970</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000094</td>\n",
       "      <td>-0.003749</td>\n",
       "      <td>0.006635</td>\n",
       "      <td>-0.003683</td>\n",
       "      <td>0.010325</td>\n",
       "      <td>0.015345</td>\n",
       "      <td>0.018697</td>\n",
       "      <td>0.004091</td>\n",
       "      <td>-0.005136</td>\n",
       "      <td>0.004314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.160970</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000094</td>\n",
       "      <td>-0.003749</td>\n",
       "      <td>0.006635</td>\n",
       "      <td>-0.003683</td>\n",
       "      <td>0.010325</td>\n",
       "      <td>0.015345</td>\n",
       "      <td>0.018697</td>\n",
       "      <td>0.004091</td>\n",
       "      <td>1.652198</td>\n",
       "      <td>-0.047345</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 74 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PTGENDER  PTEDUCAT  PTRACCAT_Asian  PTRACCAT_Black  \\\n",
       "0         0 -2.852257               0               0   \n",
       "1         1  1.376909               0               0   \n",
       "2         0  0.607970               0               0   \n",
       "3         0 -0.160970               0               0   \n",
       "4         1 -0.160970               0               0   \n",
       "\n",
       "   PTRACCAT_Hawaiian/Other_PI  PTRACCAT_More_than_one  PTRACCAT_Unknown  \\\n",
       "0                           0                       0                 0   \n",
       "1                           0                       0                 0   \n",
       "2                           0                       0                 0   \n",
       "3                           0                       0                 0   \n",
       "4                           0                       0                 0   \n",
       "\n",
       "   PTRACCAT_White  PTETHCAT_Not_Hisp/Latino  PTMARRY_Married    ...      \\\n",
       "0               1                         1                0    ...       \n",
       "1               1                         1                1    ...       \n",
       "2               1                         1                1    ...       \n",
       "3               1                         1                0    ...       \n",
       "4               1                         1                0    ...       \n",
       "\n",
       "   WholeBrain  WholeBrain_slope  Entorhinal  Entorhinal_slope  Fusiform  \\\n",
       "0   -1.761500         -0.567555   -0.820814         -1.269796 -1.426968   \n",
       "1   -0.134464         -0.028641   -0.070387          0.188014  0.721399   \n",
       "2   -1.300396          0.310720    0.456478         -0.560840  0.292776   \n",
       "3   -0.000094         -0.003749    0.006635         -0.003683  0.010325   \n",
       "4   -0.000094         -0.003749    0.006635         -0.003683  0.010325   \n",
       "\n",
       "   Fusiform_slope   MidTemp  MidTemp_slope       ICV  ICV_slope  \n",
       "0        0.156847 -2.102069      -0.192827 -1.574482   0.093937  \n",
       "1       -0.067438  0.019784       0.506511 -0.489132  -0.265646  \n",
       "2        0.016824 -0.650452       0.224140 -1.239633  -0.014198  \n",
       "3        0.015345  0.018697       0.004091 -0.005136   0.004314  \n",
       "4        0.015345  0.018697       0.004091  1.652198  -0.047345  \n",
       "\n",
       "[5 rows x 74 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_train_std.shape)\n",
    "X_train_std.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the best parameters\n",
    "cv_fold = KFold(n_splits=4, shuffle=True, random_state=9001)\n",
    "parameters = {'alpha': [1e-3, 1e-2, 1e-1, 1, 1e1, 1e2],\n",
    "              'hidden_layer_sizes': [(10), (25), (50), (100),\n",
    "                                     (10, 10), (10, 25), (10, 50), \n",
    "                                     (25, 10), (25, 25), \n",
    "                                     (50, 10)]}\n",
    "mlp = MLPClassifier(solver='lbfgs', activation='logistic', random_state=9001)\n",
    "mlp_cv = GridSearchCV(mlp, parameters, cv=cv_fold)\n",
    "mlp_cv.fit(X_train_std, y_train)\n",
    "best_score = np.argmax(mlp_cv.cv_results_['mean_test_score'])\n",
    "result = mlp_cv.cv_results_['params'][best_score]\n",
    "a = result['alpha']\n",
    "hidden_layer = result['hidden_layer_sizes']\n",
    "mlp = MLPClassifier(solver='lbfgs', activation='logistic', random_state=9001,\n",
    "                    alpha = a, hidden_layer_sizes=hidden_layer)\n",
    "mlp = mlp.fit(X_train_std, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal parameters\n",
      "L2 penalty parameter:  10.0\n",
      "Hidden Layer Sizes:  25\n",
      "\n",
      "-----------------\n",
      "\n",
      "Training accuracy:  0.824476650564\n",
      "Test accuracy:  0.777777777778\n",
      "\n",
      "-----------------\n",
      "\n",
      "Test Confusion Matrix: \n",
      "[[24 18  0]\n",
      " [ 8 79  6]\n",
      " [ 0  4 23]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Optimal parameters\")\n",
    "print(\"L2 penalty parameter: \", a)\n",
    "print(\"Hidden Layer Sizes: \", hidden_layer)\n",
    "print('\\n-----------------\\n')\n",
    "print(\"Training accuracy: \", mlp.score(X_train_std, y_train))\n",
    "print(\"Test accuracy: \", mlp.score(X_test_std, y_test))\n",
    "print('\\n-----------------\\n')\n",
    "print('Test Confusion Matrix: ')\n",
    "print(confusion_matrix(y_test, mlp.predict(X_test_std)))\n",
    "nn_score = score(mlp, X_train_std, y_train, X_test_std, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------\n",
      "\n",
      "Training accuracy:  0.972624798712\n",
      "Test accuracy:  0.796296296296\n",
      "\n",
      "-----------------\n",
      "\n",
      "Test Confusion Matrix: \n",
      "[[20 22  0]\n",
      " [ 4 87  2]\n",
      " [ 0  5 22]]\n"
     ]
    }
   ],
   "source": [
    "# random forest to compare with\n",
    "rf_best = RandomForestClassifier(n_estimators=16, max_depth=8, random_state=9001)\n",
    "rf_best.fit(X_train, y_train)\n",
    "rf_score = score(rf_best, X_train, y_train, X_test, y_test)\n",
    "print('\\n-----------------\\n')\n",
    "print(\"Training accuracy: \", rf_best.score(X_train, y_train))\n",
    "print(\"Test accuracy: \", rf_best.score(X_test, y_test))\n",
    "print('\\n-----------------\\n')\n",
    "print('Test Confusion Matrix: ')\n",
    "print(confusion_matrix(y_test, rf_best.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Neural Network</th>\n",
       "      <th>Random Forest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Train accuracy</th>\n",
       "      <td>0.824477</td>\n",
       "      <td>0.972625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test accuracy</th>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.796296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test accuracy CN</th>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.476190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test accuracy CI</th>\n",
       "      <td>0.849462</td>\n",
       "      <td>0.935484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test accuracy AD</th>\n",
       "      <td>0.851852</td>\n",
       "      <td>0.814815</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Neural Network  Random Forest\n",
       "Train accuracy          0.824477       0.972625\n",
       "Test accuracy           0.777778       0.796296\n",
       "Test accuracy CN        0.571429       0.476190\n",
       "Test accuracy CI        0.849462       0.935484\n",
       "Test accuracy AD        0.851852       0.814815"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_df = pd.DataFrame({\"Neural Network\": nn_score,\n",
    "                         \"Random Forest\": rf_score})\n",
    "score_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The optimal hidden layer size is one hidden layer with 25 neurons. We need a l2-regularization term with value 10 to achieve the best accuracy.\n",
    "\n",
    "The overall test accuracy of Neural Network is close to that of the best random forest in the previous model comparison section. However, we found that the test accuracy for the cognitive normal group and the Alzheimer's disease group is considerably higher using neural network. These two groups are what we are interested in.\n",
    "\n",
    "We would prefer neural network model to the random forest because of its high classification accuracy of Alzheimer's disease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
